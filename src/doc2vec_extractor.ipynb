{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Doc2Vec as D2V\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "from nltk import RegexpTokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import download as nltkDownload\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import db_helper\n",
    "\n",
    "import re\n",
    "\n",
    "PROJECT_PATH='/home/hmenn/Workspace/CSE496_Node2Vec_2018'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/hmenn/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/hmenn/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download nltk sources if not downloaded yet\n",
    "nltkDownload('stopwords')\n",
    "nltkDownload('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DBHelper()\n",
    "db.connect(user=\"root\",passwd=\"Hasan5695*\",db=\"cse496\")\n",
    "tweets = db.getTweets(\"denemeShort\")\n",
    "tweets.sort(key=lambda t: t.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = db_helper.getTweetsFromJson(PROJECT_PATH+'/dataset/SocialMediaDataset/tweets.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "############ Tweet: ############ \n",
       "SendByScreenName:cakrr_ \n",
       "UserID:u1623755515 \n",
       "TweetID:t763141405766250496 \n",
       "InReplyToStatusID:t763141168771244032 \n",
       "InReplyToUserID:u757176735158923264 \n",
       "Date:2016-08-10 01:34:24 \n",
       "Text:@Wesleyoloji10 OGLAK HAZİNE ARIYOR AQ:das:asd "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "stopword_set = set(stopwords.words(\"turkish\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Konut kira/satışları düşünüldüğünde piyasa öylesine şişti ki.Örneğin İstanbul'da 1000 liranın altında ev kiralamanız nerdeyse mümkün değil!\n"
     ]
    }
   ],
   "source": [
    "# clear tweets\n",
    "for tweet in tweets:\n",
    "    tweet.text = re.sub(r\"RT(^|[^@\\w])@(\\w{1,15})\\b:\",\"\",tweet.text)\n",
    "print(tweets[2].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tweets[0:100]\n",
    "dataset += tweets[3000:3050]\n",
    "dataset += tweets[5000:5100]\n",
    "dataset += tweets[8000:8050]\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlp_clean(data):\n",
    "    new_data = []\n",
    "    for d in data:\n",
    "        new_str = d.lower()\n",
    "        dlist = tokenizer.tokenize(new_str)\n",
    "        dlist = list(set(dlist).difference(stopword_set))\n",
    "        new_data.append(dlist)\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanData = nlp_clean([tweet.text for tweet in dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "taggedData = [TaggedDocument(words=word_tokenize(_d[0].lower()), tags=[str(_d[1])]) for i, _d in enumerate([(tweet.text, tweet.tweetID) for tweet in dataset])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       " TaggedDocument(words=[\"sn.cb'nımızın\", 'çağrısıyla', '3', 'banka', 'konut', 'kredisi', 'faiz', 'oranlarını', \"℅1'in\", 'altına', 'çekti..bu', 'olumlu', 'bir', 'adım', '.', 'ancak', 'şişen', 'piyasa', 'nasıl', 'düşecek', '?'], tags=['t763577912696135680']))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(taggedData)), taggedData[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hmenn/Workspace/CSE496_Node2Vec_2018/n2vEnv/lib/python3.6/site-packages/ipykernel_launcher.py:15: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 100\n",
      "iteration 200\n",
      "iteration 300\n",
      "iteration 400\n",
      "iteration 500\n",
      "CPU times: user 38.2 s, sys: 815 ms, total: 39 s\n",
      "Wall time: 39 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "max_epochs = 500\n",
    "\n",
    "model = D2V(alpha=0.025, \n",
    "                min_alpha=0.025,\n",
    "                min_count=1,\n",
    "                dm =1)\n",
    "  \n",
    "model.build_vocab(taggedData)\n",
    "\n",
    "for epoch in range(1, max_epochs+1):\n",
    "    if epoch %100 == 0:\n",
    "        print('iteration {0}'.format(epoch))\n",
    "    model.train(taggedData,\n",
    "                total_examples=model.corpus_count,\n",
    "                epochs=model.iter)\n",
    "    # decrease the learning rate\n",
    "    model.alpha -= 0.0002\n",
    "    # fix the learning rate, no decay\n",
    "    model.min_alpha = model.alpha\n",
    "    \n",
    "model.save(PROJECT_PATH + \"/outputs/tweets_d2v.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7528703228033607"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.docvecs.most_similar(\"t765296806276268032\")\n",
    "model.docvecs.similarity('t765466344707989504','t765582802343657472')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############ Tweet: ############ \n",
      "SendByScreenName:demirmadeni \n",
      "UserID:u1658471437 \n",
      "TweetID:t765466344707989504 \n",
      "InReplyToStatusID:t-1 \n",
      "InReplyToUserID:u-1 \n",
      "Date:2016-08-16 11:32:52 \n",
      "Text: Galatasaray basketbol şubesinden son haberler!\n",
      "https://t.co/WQTFKf7X3D https://t.co/T7Ex0UiHgn \n",
      "\n",
      "############ Tweet: ############ \n",
      "SendByScreenName:demarkesports \n",
      "UserID:u1499266621 \n",
      "TweetID:t765582802343657472 \n",
      "InReplyToStatusID:t-1 \n",
      "InReplyToUserID:u-1 \n",
      "Date:2016-08-16 19:15:38 \n",
      "Text:#Rio2016 Kadınlar Basketbol çeyrek final maçında Sırbistan, Avustralya'yı 73-71 mağlup etti ve yarı finale yükseldi. https://t.co/akxCoNG6nJ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t in dataset:\n",
    "    if t.tweetID==\"t765466344707989504\" or t.tweetID==\"t765582802343657472\":\n",
    "        print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "n2vEnv",
   "language": "python",
   "name": "n2venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
