In recent years, text mining has become one of the most popular research areas
in data mining, due to the rapid growth and evolution of digital text documents,
such as Web pages, office documents, and E-mails. As the demand to organize
these documents automatically is constantly rising, text classification (or text
categorization) become one active subfields for data mining researchers. Text
classification deals with the problem of automatically assigning single or multiple
category (or class) labels to a new text document based after learning from a
set of training documents with correct category labels.
Most existing text classification methods (and text mining methods at large)
adopt the approach of transforming the text mining problem into traditional
machine learning problem, where a large number of mature techniques can be
applied [7, 14, 17, 18, 8]. Usually, the conversion of a text document into a rela-
tional tuple is performed using the popular vector-space model model. Intuitively,
the document is parsed, cleaned and stemmed, in order to obtain a list of terms
with corresponding frequencies. Then a corresponding vector can be constructed
to represent the document. Therefore, a collection of documents can be repre-
sented by a term-by-frequency matrix, which can be subsequently interpreted as
a relational table.
However, the vector space model only allow preserving fundamental features
of the document. Although a few alternative weighting scheme other than term
frequency have been proposed, one common weakness is that they don’t take
into consideration the associations among terms. Recent studies have revealed
that association among terms could provide rich semantics of the documents and
serve as the basis of a number of text mining tasks [9]. However, the approach
proposed in [9] discards the vector space model and uses frequently co-occurring
terms only.
In this paper, we propose a novel model for text document by combining the
strengths of vector space model and frequently co-occurring terms together. The
result is called the term graph model. The basic idea is to mine the associations
among terms, and then capture all these information in a graph. We use text
classification to illustrate the potential application of the new model. To that
end, we design two novel similarity functions. One is based on Google’s page-rank
style algorithm [3] to discover the weights of each terms. The other is based on
the distances of all pairs of terms. Our preliminary experimental results shows
our new model is promising.
The rest of the paper is organized as follows. Section 2 introduces related
works in text classification. Section 3 presents the proposed term graph model
which is capable of capturing more information than the vector space model for
text documents. In Section 4, we propose methods to classify text documents
represented in the term graph model. Experimental results based on the Reuters-
21578 text collection is described in section 5. We conclude the paper in Section 6.
